---
title: "Sharing Arrow data between processes"
format: gfm
execute:
  echo: false
---

These are some tests to compare different methods of sharing an Arrow table 
between different processes.


```{r}
#| output: false
library(readr)
library(ggplot2)
library(dplyr)
share_data <- read_csv("share_results.csv", col_names=c("name", "time", "size_bytes")) %>%
    mutate(gbps = (size_bytes / 1024 / 1024 / 1024) / time)
retrieve_data <- read_csv("retrieve_results.csv", col_names=c("name", "time"))
```


```{r share-time}
ggplot(share_data, aes(x = name, y = time)) +
    geom_boxplot() + 
    scale_y_continuous(min = 0) + 
    labs(
        title="Time to export 100 million rows of Arrow data (about 1.5 GB)",
        x = "Transport",
        y = "Time (seconds)"
    )
```


```{r share-throughput}
ggplot(share_data, aes(x = name, y = gbps)) +
    geom_boxplot() + 
    scale_y_continuous(min = 0) + 
    labs(
        title="Throughput",
        x = "Transport",
        y = "GB per second"
    )
```


```{r share-table}
share_data %>%
    group_by(name) %>%
    summarise(
        avg_time_sec = mean(time),
        min_time_sec = min(time),
        avg_gbps = mean(gbps),
        max_gbps = max(gbps)
    )
```


```{r retrieve-time}
ggplot(retrieve_data, aes(x = name, y = time)) +
    geom_boxplot() + 
    scale_y_continuous(min = 0) + 
    labs(
        title="Time to retrieve 100 million rows of Arrow data (about 1.5 GB)",
        x = "Transport",
        y = "Time (seconds)"
    )
```


```{r}
retrieve_data %>%
    group_by(name) %>%
    summarise(
        avg_time_sec = mean(time),
        min_time_sec = min(time),
    )
```



## How to run

First start the plasma server

```shell
plasma_store -m 1000000000 -s /tmp/plasma
```

Then, start the flight server

```shell
python flight_server.py
```

Then run the share benchmarks

```

```

Finally, run the retrieve benchmarks:

```

```